### 50W-100W并发的秒杀
  - 业务分离（就是把秒杀服务器与网站其他服务器完全隔离，以防流量过大带着其他服务一起死，要死你就死吧，把配置高的服务器都用来秒杀）
  - 最前端的页面要被CDN或反向代理
  - 限流（比如服务器只能承受10W流量，高于10W的请求直接返回失败）
  - 降级（秒杀页面并发高到一定程度时可以断开某些接口查询，如推荐，相似物品，历史价格等等，减少服务器返回时间）
  - 熔断（某些接口大于某个流量活并发峰值直接返回失败,或者返回默认数据如：某些产品一直有货 ）
  - 然后进入到负载均衡器中，负载均衡器分配到web服务器中，web服务器在进入队列，之后进入一个统一的缓存计数器中，秒杀结束后，通过秒杀日志,worker计算剩余库存(此处为异步处理)
  - 并且使用ＭＱ推送下单信息至各个系统（订单，库存，发货，子业务域。。。等等系统）
  - 各个系统处理后写入数据库
这么大流量的系统想要保证数据库中与前台库存与缓存的一致性几乎不可能，但是我们只要保证最终落表的数据是正确的就行,如同上文中使用worker读取日志采用异步的方式进行数据落表处理(当然方法还有很多，这里只介绍一个典型方案)，这就是传说中的弱一致性保持，分布式系统CAP中通常都会牺牲掉C

另有方案:
秒杀的核心是流量筛选！让用户先领一波票（票比货多点），凭票进场下单。
因为判断用户是否有票是一个成本极低的操作，单服务器怼几十万并发都没问题。而下单则是成本较高的操作，只要前面有个检票的拦着不让没票的进，就那么百十来个有票的用户还有什么伺候不过来的

#### 高并发下怎么做余额扣减？
1.高并发，单纯数据库update更新账户余额，数据库的update行锁已经成为瓶颈。
2.扣减要保证不能扣为负数。
ps:两个典型的场景
1.扣费，企业账户送流量或者红包，用户签到领取。目前我了解到的方案就是分多账户降低单账户的压力或者更新改插入异步去计算余额。
2.充值，打赏给主播，方案类似

余额业务的高并发难点分成以下几个层次:
- 单应用，单数据库 在这个层次，只需要选择合适的单机数据库选型，做好业务场景就OK了 推荐的TPS 在5w以下，最好的优化 + 32核心64GB + io打满也不会大于30w
- 单应用，多数据库 使用分库来解决数据库横向扩容的问题来增加TPS
- 多应用，多数据库 多了一个新的问题，分布式一致性事务,一般来说，好的业务都能通过一些关系字段来很好规避分布式事务的问题，而且一个设计中也应该杜绝大量的跨库事务

怎么解决好多个应用间的分布式一致性事务问题:
解决多应用之间的分布式一致性问题，目前基本分为两个思路：
- 1 补偿型事务
- 2 确保通知型事务

1. 作为比较，先说下一般的acid二阶段递交的流程，dml阶段先锁行，一阶段写redo，二阶段再做真递交+解锁行，这种模型非常慢，latency很大
2. 补偿性事务就是一阶段的时候都直接递交，这样一阶段都成功的话，二阶段可以快速返回，如一阶段有参与者失败，则再使用一条补偿操作，把一阶段的递交给补偿回来
3. 确保通知型事务则是，发起者先落库，然后再发出一条事务型消息，确保消息发出后，直接返回（此时参与者很多都未落库）

这两个方式的出发点是一致的，普通两阶段，锁行的时间长，返回等待的时间长，无法很好的利用好机器性能，所以牺牲一点一致性，让业务等待时间缩短

然后再回来说余额类业务，余额型业务的业务特点决定了他非常适合补偿型的事务，由于余额是一个数字的加减，这意味着，加减的顺序不影响最终值，所以它天然适合这类牺牲一定一致性的事务。余额类的使用方式:
1. 每个余额类应用都可以在一阶段更新余额 update amount = amount - 消费金额 ，而补偿操作很简单，就是 update amount = amount + 消费金额
2. 如果不想让使用者看到这个不一致的过程，可以再设置一个冻结金额表，第一阶段操作冻结金额的表，二阶段把冻结金额更新到余额上
3. 如果不想让余额被两个同时来的消费请求扣减为负数（也就是第二个请求来时，第一个请求扣减未生效），可以让一阶段检查 余额 - sum(冻结金额），然后再产生一笔新的冻结金额

热点账户问题抽象出来就是单机处理能力的问题，一般这种问题就两种解法.
对于扣费：
- batch 把一定逻辑时间范围类的请求合并提交，降低对数据库的压力，牺牲一定的延时，不过在高并发下，可以把一个buket的范围缩小到50ms左右，用户一般无感知。
- 拆 ： 把一个热点账户拆成各个子账户，分库表到不同的机器上，balance请求压力(账户余额假如也平均分配)。业务逻辑层面维护一个datasource list。当发现某一次扣减失败。这里注意下，如果是红包之类的扣减，一个包的大小基本上很小，如果扣减失败，基本上可以放弃这个子账户，降低这个账户在datasource list中的权重。最后到了一个临界点(基本都不剩什么钱)，就表示红包被抢完了。这种方式会牺牲一些可用性，但是至少不存在有超卖的情况



[究竟啥才是互联网架构“高并发”](https://zhuanlan.zhihu.com/p/24830094)

互联网分布式架构设计，提高系统并发能力的方式，方法论上主要有两种：垂直扩展（Scale Up）与水平扩展（Scale Out）。
垂直扩展：提升单机处理能力。垂直扩展的方式又有两种：

（1）增强单机硬件性能，例如：增加CPU核数如32核，升级更好的网卡如万兆，升级更好的硬盘如SSD，扩充硬盘容量如2T，扩充系统内存如128G；

（2）提升单机架构性能，例如：使用Cache来减少IO次数，使用异步来增加单服务吞吐量，使用无锁数据结构来减少响应时间；
在互联网业务发展非常迅猛的早期，如果预算不是问题，强烈建议使用“增强单机硬件性能”的方式提升系统并发能力，因为这个阶段，公司的战略往往是发展业务抢时间，而“增强单机硬件性能”往往是最快的方法。

水平扩展：只要增加服务器数量，就能线性扩充系统性能。水平扩展对系统架构设计是有要求的，如何在架构各层进行可水平扩展的设计，以及互联网公司架构各层常见的水平扩展实践，是本文重点讨论的内容

常见的互联网分层架构
![](https://i.loli.net/2018/03/14/5aa884c1a68a6.png)
- 客户端层：典型调用方是浏览器browser或者手机应用APP
- 反向代理层：系统入口，反向代理
- 站点应用层：实现核心应用逻辑，返回html或者json
- 服务层：如果实现了服务化，就有这一层
- 数据-缓存层：缓存加速访问存储
- 数据-数据库层：数据库固化数据存储

整个系统各层次的水平扩展，又分别是如何实施的呢？
反向代理层的水平扩展：
![](https://i.loli.net/2018/03/14/5aa88517616c6.png)
反向代理层的水平扩展，是通过“DNS轮询”实现的：dns-server对于一个域名配置了多个解析ip，每次DNS解析请求来访问dns-server，会轮询返回这些ip。
当nginx成为瓶颈的时候，只要增加服务器数量，新增nginx服务的部署，增加一个外网ip，就能扩展反向代理层的性能，做到理论上的无限高并发

站点层的水平扩展：
![](https://i.loli.net/2018/03/14/5aa886662c99d.png)
当web后端成为瓶颈的时候，只要增加服务器数量，新增web服务的部署，在nginx配置中配置上新的web后端，就能扩展站点层的性能，做到理论上的无限高并发。

数据层的水平扩展：
在数据量很大的情况下，数据层（缓存，数据库）涉及数据的水平扩展，将原本存储在一台服务器上的数据（缓存，数据库）水平拆分到不同服务器上去，以达到扩充系统性能的目的。

数据库可以按照数据范围，或者数据哈希的方式来进行水平扩展


#### java web系统在高并发下如何实现订单号生成唯一
切记减少内存式锁生产。这样的设计一看就知道是象牙塔出来的，没真的经历过。一般来说这种流水号，在需要的时候再惰性生成，就已经晚了，要考虑负载前置。你的业务场景不充分，补充更多业务场景可能会导致solution变化，但是就目前这样的做思考题来说已经足够。首先你的业务场景有一个前提，订单号并不需要严格按照进入系统的时间来区分流水先后，因为你已经是高并发了，快1，2个毫秒，订单号一定要按顺序，这除非找茬，不会真实存在于系统之中。所以，你可以采取高性能Q，预先生成流水号（关键点1），按照业务量分片（关键点2），进行分级缓存（关键点3）。一级缓存肯定在内存里，你可以准备大约10秒的流水号在内存里。由十个分片控制，在业务逻辑取流水的时候，由算法控制去不同片取。（轮询也好，计数也好，这都随便，看你业务场景）这样的话，好处是你加锁等待时间，平均来说，除以10了。切记架构设计是软硬件一体设计，二级缓存放在高性能SSD里面，每5秒查询下一级缓存是否接近临界值（比如流水还剩15%），则尾端补充
